import os
import re
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Qdrant
from qdrant_client import QdrantClient
from langchain.agents import create_react_agent, Tool, AgentExecutor
from langchain.prompts import PromptTemplate
from loguru import logger
from .memory_manager import StaffMemoryManager
# åŒ¯å…¥ Agent Prompt
from prompts import CONTENT_GENERATION_AGENT_PROMPT

class ContentGenerator:
    """
    æ–‡æ¡ˆç”Ÿæˆæœå‹™ (Agent ç‰ˆ)
    è·è²¬ï¼šæ•´åˆ LLMã€è¨˜æ†¶èˆ‡çŸ¥è­˜åº«å·¥å…·ï¼Œä¸»å‹•æŸ¥è­‰å¾Œç”Ÿæˆæ–‡æ¡ˆ
    """
    
    def __init__(self, memory_manager: StaffMemoryManager):
        self.memory_manager = memory_manager
        # 1. åˆå§‹åŒ– LLM
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash-001",
            google_api_key=os.getenv("GEMINI_API_KEY"),
            temperature=0.4,
            max_output_tokens=2048
        )
        
        # 2. åˆå§‹åŒ– Embeddings
        self.embeddings = HuggingFaceEmbeddings(
            model_name="moka-ai/m3e-base",
            model_kwargs={'device': 'cpu'}
        )
        
        # 3. åˆå§‹åŒ–çŸ¥è­˜åº«é€£ç·š
        self.vectorstore = Qdrant(
            client=QdrantClient(
                host=os.getenv("QDRANT_HOST", "qdrant"),
                port=int(os.getenv("QDRANT_PORT", 6333))
            ),
            collection_name="pais_knowledge_base",
            embeddings=self.embeddings
        )
        
        # 4. åˆå§‹åŒ–å·¥å…·
        self.tools = [
            Tool(
                name="KnowledgeSearch",
                func=self._search_knowledge_base,
                description="ç”¨æ–¼æœå°‹æ¡ƒåœ’å¸‚çš„æ”¿ç­–ã€æ•¸æ“šã€æ´»å‹•ç´°ç¯€æˆ–å¸‚é•·ç™¼è¨€ã€‚è¼¸å…¥é—œéµå­—å³å¯ã€‚"
            )
        ]
        
        # 5. åˆå§‹åŒ– Agent
        self.prompt = PromptTemplate(
            template=CONTENT_GENERATION_AGENT_PROMPT,
            input_variables=["input", "chat_history", "agent_scratchpad", "tools", "tool_names"]
        )
        
        self.agent = create_react_agent(self.llm, self.tools, self.prompt)
        self.agent_executor = AgentExecutor(
            agent=self.agent, 
            tools=self.tools, 
            verbose=True, 
            handle_parsing_errors=True,
            max_iterations=5
        )
        
        logger.info("âœ… ContentGenerator (Agent Mode) Ready")

    def _clean_text(self, text: str) -> str:
        if not text: return ""
        return re.sub(r'[\{\}]', '', text)

    def _search_knowledge_base(self, query: str) -> str:
        """Agent ä½¿ç”¨çš„æœå°‹å·¥å…·"""
        safe_query = self._clean_text(query)
        logger.info(f"ğŸ” [æ–‡æ¡ˆç”Ÿæˆ] Agent æ­£åœ¨æŸ¥è­‰: {safe_query}")
        try:
            docs = self.vectorstore.similarity_search(safe_query, k=3)
            if docs:
                contents = [self._clean_text(d.page_content) for d in docs]
                result = "\n\n".join(contents)
                return f"ã€æŸ¥è­‰çµæœã€‘:\n{result[:2000]}"
            return "çŸ¥è­˜åº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œè³‡æ–™ã€‚"
        except Exception as e:
            return f"æœå°‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"

    async def generate(self, task_id: str, topic: str, style: str, length: str) -> str:
        """åŸ·è¡Œæ–‡æ¡ˆç”Ÿæˆ (Agent æµç¨‹)"""
        try:
            # é€™è£¡æœƒå‘¼å« self.memory_managerï¼Œå¦‚æœ __init__ æ²’è¨­å®šå¥½å°±æœƒå ±éŒ¯
            memory = self.memory_manager.get_memory(task_id)
            history = memory.load_memory_variables({})["chat_history"]

            user_input = f"æ’°å¯«ä¸€ä»½ã€Œ{style}ã€é¢¨æ ¼çš„æ–‡æ¡ˆï¼Œä¸»é¡Œæ˜¯ã€Œ{topic}ã€ï¼Œç¯‡å¹…è¦æ±‚ã€Œ{length}ã€ã€‚è«‹å‹™å¿…å…ˆæŸ¥è­‰ç›¸é—œè³‡æ–™ã€‚"

            logger.info(f"ğŸš€ é–‹å§‹ç”Ÿæˆæ–‡æ¡ˆ (Task: {task_id})")
            
            result = await self.agent_executor.ainvoke({
                "input": user_input,
                "chat_history": history
            })
            
            content = result.get("output", "").strip()

            memory.save_context(
                {"input": f"ç”Ÿæˆæ–‡æ¡ˆ: {topic}"},
                {"text": content}
            )
            
            return content

        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡ˆç”Ÿæˆå¤±æ•—: {e}")
            raise e

    def save_edit_feedback(self, task_id: str, original: str, edited: str):
        self.memory_manager.save_feedback(task_id, original, edited)