"""
æ–‡æ¡ˆç”Ÿæˆæœå‹™ (å¸¶è¨˜æ†¶åŠŸèƒ½)
éµå¾ª Single Responsibility Principleï¼šå°ˆæ³¨æ–¼æ–‡æ¡ˆç”Ÿæˆé‚è¼¯
"""
import os
from typing import Optional
from langchain_google_genai import GoogleGenerativeAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_community.vectorstores import Qdrant
from qdrant_client import QdrantClient
from langchain_community.embeddings import HuggingFaceEmbeddings
from loguru import logger

from .memory_manager import StaffMemoryManager


class ContentGenerator:
    """æ–‡æ¡ˆç”Ÿæˆå™¨ (å¸¶è¨˜æ†¶å­¸ç¿’åŠŸèƒ½)"""
    
    def __init__(
        self, 
        memory_manager: StaffMemoryManager,
        gemini_api_key: Optional[str] = None,
        qdrant_host: str = "qdrant",
        qdrant_port: int = 6333
    ):
        self.memory_manager = memory_manager
        
        # åˆå§‹åŒ– LLM
        api_key = gemini_api_key or os.getenv("GEMINI_API_KEY")
        self.llm = GoogleGenerativeAI(
            model="gemini-2.0-flash",
            google_api_key=api_key,
            temperature=0.7,
            max_output_tokens=1024
        )
        
        # åˆå§‹åŒ–å‘é‡è³‡æ–™åº« (å…±ç”¨çŸ¥è­˜åº«)
        embeddings = HuggingFaceEmbeddings(
            model_name="moka-ai/m3e-base",
            model_kwargs={'device': 'cpu'}
        )
        
        qdrant_client = QdrantClient(host=qdrant_host, port=qdrant_port)
        self.vectorstore = Qdrant(
            client=qdrant_client,
            collection_name="pais_knowledge_base",
            embeddings=embeddings
        )
        
        # å»ºç«‹ Prompt æ¨¡æ¿
        self.prompt = self._build_prompt()
        logger.info("âœ… æ–‡æ¡ˆç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _build_prompt(self) -> PromptTemplate:
        """å»ºç«‹æ–‡æ¡ˆç”Ÿæˆ Promptï¼ˆå„ªåŒ–ç‰ˆ - å¼·åŒ–å­¸ç¿’èƒ½åŠ›ï¼‰"""
        return PromptTemplate(
            template="""ä½ æ˜¯æ¡ƒåœ’å¸‚é•·å¼µå–„æ”¿çš„å°ˆå±¬æ–‡æ¡ˆåŠ©ç†ï¼Œè² è²¬å”åŠ©æ’°å¯«å„é¡å¸‚æ”¿æ–‡å®£ã€‚ä½ çš„ä»»å‹™æ˜¯æ¨¡ä»¿å¸‚é•·çš„èªæ°£é¢¨æ ¼ï¼Œå‰µä½œè²¼è¿‘æ°‘æ„ã€å°ˆæ¥­ä¸”æº«æš–çš„æ–‡æ¡ˆã€‚

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ğŸ“š éå¾€å­¸ç¿’è¨˜æ†¶ã€‘
{chat_history}

**é‡è¦ï¼š** ä»”ç´°é–±è®€ä¸Šæ–¹çš„éå¾€è¨˜éŒ„ï¼Œç‰¹åˆ¥æ³¨æ„ï¼š
1. å¹•åƒšéå»ä¿®æ”¹éå“ªäº›ç”¨è©ï¼Ÿå­¸ç¿’ä»–å€‘çš„ä¿®æ”¹æ–¹å‘
2. å“ªäº›è¡¨é”æ–¹å¼è¢«ä¿ç•™ï¼Ÿä»£è¡¨é€™æ˜¯å¥½çš„å¯«æ³•
3. å¸‚é•·å¸¸ç”¨çš„é–‹é ­ã€çµå°¾ã€è½‰æŠ˜è©å½™
4. é¿å…é‡è¤‡ä½¿ç”¨éå»è¢«ä¿®æ­£çš„éŒ¯èª¤è¡¨é”

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ğŸ¯ æœ¬æ¬¡ä»»å‹™ã€‘
- ğŸ“‹ ä¸»é¡Œï¼š{topic}
- ğŸ¨ é¢¨æ ¼ï¼š{style}
- ğŸ“ é•·åº¦ï¼š{length}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ğŸ“– åƒè€ƒè³‡æ–™ï¼ˆçŸ¥è­˜åº«ï¼‰ã€‘
{context}

**æ³¨æ„ï¼š** å…§å®¹å¿…é ˆåŸºæ–¼ä¸Šè¿°åƒè€ƒè³‡æ–™ï¼Œç¢ºä¿æ•¸æ“šã€æ—¥æœŸã€æ”¿ç­–åç¨±çš„æº–ç¢ºæ€§ã€‚

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€âœï¸ å¸‚é•·èªæ°£é¢¨æ ¼æŒ‡å—ã€‘

**å¸‚é•·çš„èªè¨€ç‰¹è‰²ï¼š**
1. **è¦ªæ°‘æ¥åœ°æ°£**ï¼šä½¿ç”¨ã€Œæˆ‘å€‘ä¸€èµ·ã€ã€Œå’±å€‘æ¡ƒåœ’ã€ç­‰æ‹‰è¿‘è·é›¢çš„ç”¨èª
2. **ç§‘æŠ€ç†æ€§**ï¼šé©åº¦èå…¥æ•¸æ“šã€ç§‘æŠ€æ¦‚å¿µï¼ˆå¸‚é•·æœ‰ç§‘æŠ€èƒŒæ™¯ï¼‰
3. **å‹™å¯¦ç©©å¥**ï¼šå¼·èª¿ã€Œåšå¾—åˆ°æ‰èªªã€ã€Œèªªåˆ°åšåˆ°ã€çš„æ‰¿è«¾
4. **æº«æš–é—œæ‡·**ï¼šå°å¸‚æ°‘ã€å¼±å‹¢ç¾¤é«”è¡¨é”çœŸèª é—œå¿ƒ
5. **åœ˜éšŠç²¾ç¥**ï¼šå¸¸æåŠã€Œå¸‚åºœåœ˜éšŠã€ã€Œå¤§å®¶å…±åŒåŠªåŠ›ã€

**å¸¸ç”¨å¥å‹ç¯„ä¾‹ï¼š**
- é–‹é ­ï¼šã€Œå„ä½é„‰è¦ªã€ã€Œå¸‚æ°‘æœ‹å‹ã€ã€Œå’±å€‘æ¡ƒåœ’äººã€
- æ‰¿è«¾ï¼šã€Œæˆ‘æœƒç¹¼çºŒåŠªåŠ›ã€ã€Œå¸‚åºœåœ˜éšŠæœƒå…¨åŠ›ä»¥èµ´ã€
- æ„Ÿè¬ï¼šã€Œè¬è¬å¤§å®¶çš„æ”¯æŒã€ã€Œæ„Ÿè¬å¸‚æ°‘çš„ä¿¡ä»»ã€
- è™Ÿå¬ï¼šã€Œè®“æˆ‘å€‘ä¸€èµ·æ‰“æ‹¼ã€ã€Œå…±åŒç‚ºæ¡ƒåœ’åŠªåŠ›ã€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ğŸ“ é¢¨æ ¼èˆ‡é•·åº¦è¦ç¯„ã€‘

**é¢¨æ ¼å®šç¾©ï¼š**
- **formalï¼ˆæ­£å¼ï¼‰**ï¼š
  * ç”¨æ–¼æ”¿ç­–ç™¼å¸ƒã€å®˜æ–¹è²æ˜ã€é‡è¦å ´åˆè‡´è©
  * èªæ°£èŠé‡ä½†ä¸å¤±è¦ªå’Œï¼Œä½¿ç”¨å®Œæ•´å¥å¼
  * ç¯„ä¾‹é–‹é ­ï¼šã€Œå„ä½å¸‚æ°‘æœ‹å‹ï¼Œå¤§å®¶å¥½ã€

- **casualï¼ˆè¼•é¬†è¦ªåˆ‡ï¼‰**ï¼š
  * ç”¨æ–¼ç¤¾ç¾¤åª’é«”ã€æ—¥å¸¸äº’å‹•ã€æ´»å‹•å®£å‚³
  * èªæ°£è¼•é¬†è‡ªç„¶ï¼Œå¯ç”¨ç°¡çŸ­å¥ã€å•å¥äº’å‹•
  * ç¯„ä¾‹é–‹é ­ï¼šã€Œå¤§å®¶å¥½ï¼ä»Šå¤©è¦è·Ÿå„ä½åˆ†äº«ä¸€å€‹å¥½æ¶ˆæ¯ã€

- **humorousï¼ˆå¹½é»˜é¢¨è¶£ï¼‰**ï¼š
  * ä¿æŒå°ˆæ¥­ä½†åŠ å…¥è¼•é¬†å¹½é»˜å…ƒç´ 
  * å¯ç”¨æ¯”å–»ã€ç”Ÿæ´»åŒ–çš„ä¾‹å­
  * ç¯„ä¾‹ï¼šã€Œå¸‚æ”¿å»ºè¨­å°±åƒç…®ä¸€é‹å¥½æ¹¯ï¼Œè¦æ…¢å·¥å‡ºç´°æ´»ã€

- **conciseï¼ˆç²¾ç°¡æœ‰åŠ›ï¼‰**ï¼š
  * ç”¨æ–¼æµ·å ±æ¨™èªã€é‡é»å®£å‚³
  * ç²¾ç…‰æ–‡å­—ï¼Œæ¯å¥è©±éƒ½æœ‰åŠ›é‡
  * ç¯„ä¾‹ï¼šã€Œèªªåˆ°åšåˆ°ï¼Œç‚ºæ¡ƒåœ’æ‰“æ‹¼ã€

**é•·åº¦è¦æ±‚ï¼š**
- **short**ï¼š50-100å­—ï¼ˆé©åˆæ¨™èªã€çŸ­è²¼æ–‡ï¼‰
- **medium**ï¼š150-300å­—ï¼ˆé©åˆä¸€èˆ¬ç¤¾ç¾¤è²¼æ–‡ã€æ–°èç¨¿å¼•è¨€ï¼‰
- **long**ï¼š400-600å­—ï¼ˆé©åˆå®Œæ•´æ–°èç¨¿ã€æ¼”è¬›ç¨¿ï¼‰

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€âš ï¸ æ³¨æ„äº‹é …ã€‘

1. **å¿…é ˆåŸºæ–¼äº‹å¯¦**ï¼šä¸ç·¨é€ æ•¸æ“šã€æ—¥æœŸã€æ”¿ç­–å…§å®¹
2. **å­¸ç¿’è¨˜æ†¶**ï¼šå¾éå¾€ä¿®æ”¹è¨˜éŒ„ä¸­å­¸ç¿’æ­£ç¢ºè¡¨é”
3. **ä¿æŒä¸€è‡´æ€§**ï¼šç”¨è©é¢¨æ ¼è¦èˆ‡å¸‚é•·å½¢è±¡ä¸€è‡´
4. **é¿å…æ”¿æ²»æ•æ„Ÿ**ï¼šä¸æ¶‰åŠé¸èˆ‰ã€æ”¿é»¨æ”»æ“Š
5. **æ•¸å­—ç²¾ç¢º**ï¼šæ¶‰åŠé ç®—ã€äººæ•¸ç­‰æ•¸æ“šè¦æº–ç¢ºå¼•ç”¨

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€âœ¨ é–‹å§‹ç”Ÿæˆã€‘

è«‹æ ¹æ“šä»¥ä¸Šæ‰€æœ‰æŒ‡å¼•ï¼Œç”Ÿæˆç¬¦åˆè¦æ±‚çš„æ–‡æ¡ˆã€‚**åªè¼¸å‡ºæ–‡æ¡ˆæœ¬èº«ï¼Œä¸è¦æœ‰ä»»ä½•èªªæ˜æˆ–å‚™è¨»**ã€‚

æ–‡æ¡ˆå…§å®¹ï¼š""",
            input_variables=["topic", "style", "length", "context", "chat_history"]
        )
    
    async def generate(
        self, 
        task_id: str, 
        topic: str, 
        style: str, 
        length: str
    ) -> str:
        """
        ç”Ÿæˆæ–‡æ¡ˆ
        
        Args:
            task_id: ä»»å‹™ ID
            topic: æ–‡æ¡ˆä¸»é¡Œ
            style: é¢¨æ ¼ (formal/casual/humorous)
            length: é•·åº¦ (short/medium/long)
        
        Returns:
            ç”Ÿæˆçš„æ–‡æ¡ˆå…§å®¹
        """
        try:
            # å¾çŸ¥è­˜åº«æª¢ç´¢ç›¸é—œè³‡æ–™
            context = self._retrieve_context(topic)

            # å–å¾—è¨˜æ†¶ä¸¦æ‰‹å‹•æå– chat_history
            memory = self.memory_manager.get_memory(task_id)
            chat_history = memory.load_memory_variables({}).get("chat_history", "")

            # å»ºç«‹ Chainï¼ˆä¸ä½¿ç”¨è‡ªå‹• memoryï¼Œæ‰‹å‹•å‚³å…¥ chat_historyï¼‰
            chain = LLMChain(
                llm=self.llm,
                prompt=self.prompt,
                verbose=True
            )

            # ç”Ÿæˆæ–‡æ¡ˆ
            logger.info(f"ğŸš€ é–‹å§‹ç”Ÿæˆæ–‡æ¡ˆ: {task_id} - {topic}")
            result = await chain.ainvoke({
                "topic": topic,
                "style": style,
                "length": length,
                "context": context,
                "chat_history": chat_history
            })

            content = result["text"].strip()

            # æ‰‹å‹•ä¿å­˜åˆ°è¨˜æ†¶
            memory.save_context(
                {"input": f"ç”Ÿæˆæ–‡æ¡ˆ - ä¸»é¡Œ: {topic}, é¢¨æ ¼: {style}, é•·åº¦: {length}"},
                {"text": content}
            )

            # è¨˜éŒ„ç”Ÿæˆçµæœåˆ°è¨˜æ†¶
            self.memory_manager.add_generation_record(
                task_id, topic, style, content
            )

            logger.info(f"âœ… æ–‡æ¡ˆç”Ÿæˆå®Œæˆ: {task_id} ({len(content)} å­—)")
            return content
            
        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡ˆç”Ÿæˆå¤±æ•—: {task_id} - {e}")
            raise
    
    def _retrieve_context(self, topic: str, k: int = 3) -> str:
        """å¾çŸ¥è­˜åº«æª¢ç´¢ç›¸é—œè³‡æ–™"""
        try:
            retriever = self.vectorstore.as_retriever(search_kwargs={"k": k})
            docs = retriever.invoke(topic)
            
            if docs:
                context = "\n\n".join([doc.page_content for doc in docs])
                logger.info(f"ğŸ“š æª¢ç´¢åˆ° {len(docs)} ç­†ç›¸é—œè³‡æ–™")
                return context[:2000]  # é™åˆ¶é•·åº¦
            else:
                logger.warning("âš ï¸ çŸ¥è­˜åº«ä¸­æœªæ‰¾åˆ°ç›¸é—œè³‡æ–™")
                return "ï¼ˆç„¡ç‰¹å®šåƒè€ƒè³‡æ–™ï¼‰"
                
        except Exception as e:
            logger.error(f"âŒ æª¢ç´¢çŸ¥è­˜åº«å¤±æ•—: {e}")
            return "ï¼ˆæª¢ç´¢å¤±æ•—ï¼‰"
    
    def save_edit_feedback(self, task_id: str, original: str, edited: str):
        """å„²å­˜äººå·¥ä¿®æ”¹ä½œç‚ºå­¸ç¿’æ¨£æœ¬"""
        self.memory_manager.save_feedback(task_id, original, edited)
        logger.info(f"ğŸ“š å·²å„²å­˜ä¿®æ”¹è¨˜éŒ„ä½œç‚ºå­¸ç¿’æ¨£æœ¬: {task_id}")