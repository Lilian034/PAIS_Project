import os
import json
from datetime import datetime
from typing import List, Optional, Dict, Any
from pathlib import Path

from fastapi import FastAPI, HTTPException, UploadFile, File, Depends, Header
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ==================== LangChain æ ¸å¿ƒ ====================
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import (
    PyPDFLoader, Docx2txtLoader, TextLoader
)
from langchain_community.vectorstores import Qdrant
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams

# ==================== LangChain Agents ====================
from langchain.agents import AgentExecutor, create_react_agent, Tool
from langchain.prompts import PromptTemplate

# ==================== LangChain Memory ====================
from langchain.memory import ConversationBufferMemory
from langchain_community.chat_message_histories import FileChatMessageHistory

# ==================== LangChain Chains ====================
from langchain.chains import (
    ConversationalRetrievalChain,
    LLMChain
)

from dotenv import load_dotenv
from loguru import logger

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# ==================== é…ç½® ====================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
QDRANT_HOST = os.getenv("QDRANT_HOST", "qdrant")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
ADMIN_PASSWORD = os.getenv("ADMIN_PASSWORD", "admin123456")
COLLECTION_NAME = "pais_knowledge_base"

# è¨­å®šæ—¥èªŒ
logger.add("logs/pais_{time}.log", rotation="1 day", retention="30 days")

# ==================== FastAPI æ‡‰ç”¨ ====================
app = FastAPI(
    title="PAIS - æ”¿å‹™åˆ†èº«æ™ºèƒ½ç³»çµ± (LangChain Powered)",
    description="åŸºæ–¼ LangChain çš„å¸‚é•·èŠå¤©æ©Ÿå™¨äºº (Agents + Memory + RAG + Tools)",
    version="2.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== LangChain åˆå§‹åŒ– ====================

# Gemini LLM
llm = GoogleGenerativeAI(
    model="gemini-pro",
    google_api_key=GEMINI_API_KEY,
    temperature=0.7,
    max_output_tokens=2048
)

# Gemini Embeddings
embeddings = GoogleGenerativeAIEmbeddings(
    model="models/embedding-001",
    google_api_key=GEMINI_API_KEY
)

# ä½¿ç”¨æœ¬åœ° HuggingFace Embeddingsï¼ˆå…è²»ï¼Œä¸éœ€è¦ APIï¼‰
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-mpnet-base-v2",
    model_kwargs={'device': 'cpu'}
)

# Qdrant å‘é‡è³‡æ–™åº«
qdrant_client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)

try:
    qdrant_client.get_collection(COLLECTION_NAME)
    logger.info(f"âœ… é›†åˆ '{COLLECTION_NAME}' å·²å­˜åœ¨")
except Exception:
    qdrant_client.create_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=VectorParams(size=768, distance=Distance.COSINE)
    )
    logger.info(f"âœ… å·²å»ºç«‹æ–°é›†åˆ '{COLLECTION_NAME}'")

vectorstore = Qdrant(
    client=qdrant_client,
    collection_name=COLLECTION_NAME,
    embeddings=embeddings
)

# ==================== LangChain Memory ç®¡ç† ====================
memory_store: Dict[str, ConversationBufferMemory] = {}

def get_memory(session_id: str) -> ConversationBufferMemory:
    """å–å¾—æˆ–å»ºç«‹å°è©±è¨˜æ†¶"""
    if session_id not in memory_store:
        message_history = FileChatMessageHistory(f"chat_history/{session_id}.json")
        memory_store[session_id] = ConversationBufferMemory(
            chat_memory=message_history,
            memory_key="chat_history",
            return_messages=True,
            output_key="answer"
        )
        logger.info(f"ğŸ§  å»ºç«‹æ–°è¨˜æ†¶: {session_id}")
    return memory_store[session_id]

# ==================== LangChain Tools ====================

def search_knowledge_base(query: str) -> str:
    """æœå°‹çŸ¥è­˜åº«å·¥å…·"""
    try:
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        docs = retriever.get_relevant_documents(query)
        if docs:
            result = "\n\n".join([doc.page_content for doc in docs])
            return f"æ‰¾åˆ°ç›¸é—œè³‡æ–™ï¼š\n{result}"
        return "æœªæ‰¾åˆ°ç›¸é—œè³‡æ–™"
    except Exception as e:
        return f"æœå°‹éŒ¯èª¤: {str(e)}"

def get_policy_info(policy_name: str) -> str:
    """å–å¾—æ”¿ç­–è³‡è¨Šå·¥å…·"""
    try:
        docs = vectorstore.similarity_search(policy_name, k=2)
        if docs:
            return f"æ”¿ç­–è³‡è¨Šï¼š{docs[0].page_content}"
        return f"æœªæ‰¾åˆ° '{policy_name}' ç›¸é—œæ”¿ç­–"
    except Exception as e:
        return f"æŸ¥è©¢éŒ¯èª¤: {str(e)}"

def save_generated_content(content: str, topic: str) -> str:
    """å„²å­˜ç”Ÿæˆå…§å®¹å·¥å…·"""
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"generated_content/{timestamp}_{topic[:20]}.txt"
        Path("generated_content").mkdir(exist_ok=True)
        
        with open(filename, "w", encoding="utf-8") as f:
            f.write(content)
        
        return f"âœ… å…§å®¹å·²å„²å­˜è‡³: {filename}"
    except Exception as e:
        return f"å„²å­˜å¤±æ•—: {str(e)}"

# å®šç¾© Agent å·¥å…·
tools = [
    Tool(
        name="æœå°‹çŸ¥è­˜åº«",
        func=search_knowledge_base,
        description="ç•¶éœ€è¦æŸ¥è©¢å¸‚é•·çš„æ”¿ç­–ã€ç†å¿µã€éå¾€ç™¼è¨€æ™‚ä½¿ç”¨ã€‚è¼¸å…¥ï¼šå•é¡Œæˆ–é—œéµå­—"
    ),
    Tool(
        name="æŸ¥è©¢æ”¿ç­–",
        func=get_policy_info,
        description="æŸ¥è©¢ç‰¹å®šæ”¿ç­–çš„è©³ç´°è³‡è¨Šã€‚è¼¸å…¥ï¼šæ”¿ç­–åç¨±"
    ),
    Tool(
        name="å„²å­˜å…§å®¹",
        func=save_generated_content,
        description="å„²å­˜ç”Ÿæˆçš„æ–‡æ¡ˆå…§å®¹ã€‚è¼¸å…¥ï¼šå…§å®¹æ–‡å­—,ä¸»é¡Œ"
    )
]

# ==================== LangChain Agent å®šç¾© ====================

AGENT_PROMPT = """ä½ æ˜¯å¸‚é•·çš„æ™ºèƒ½ AI åŠ©ç†ã€Œå–„å¯¶ã€ï¼Œè² è²¬èˆ‡æ°‘çœ¾äº’å‹•ã€‚

ä½ çš„è·è²¬ï¼š
1. ä½¿ç”¨å¸‚é•·è¦ªåˆ‡ã€å°ˆæ¥­çš„èªæ°£å›ç­”å•é¡Œ
2. æ ¹æ“šçŸ¥è­˜åº«æä¾›æº–ç¢ºè³‡è¨Š
3. ä¿æŒå°è©±çš„é€£è²«æ€§å’Œè¨˜æ†¶
4. é©æ™‚ä½¿ç”¨å¹½é»˜æ„Ÿæ‹‰è¿‘è·é›¢

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
{tools}

å·¥å…·åç¨±ï¼š{tool_names}

ä½¿ç”¨æ ¼å¼ï¼š
Question: è¼¸å…¥çš„å•é¡Œ
Thought: æ€è€ƒå¦‚ä½•å›ç­”
Action: é¸æ“‡ä½¿ç”¨çš„å·¥å…·
Action Input: å·¥å…·çš„è¼¸å…¥
Observation: å·¥å…·çš„è¼¸å‡º
... (é‡è¤‡ Thought/Action/Observation ç›´åˆ°æœ‰ç­”æ¡ˆ)
Thought: æˆ‘ç¾åœ¨çŸ¥é“æœ€çµ‚ç­”æ¡ˆäº†
Final Answer: æœ€çµ‚å›ç­”

å°è©±è¨˜éŒ„ï¼š
{chat_history}

é–‹å§‹ï¼

Question: {input}
Thought: {agent_scratchpad}"""

agent_prompt = PromptTemplate(
    template=AGENT_PROMPT,
    input_variables=["input", "chat_history", "agent_scratchpad", "tools", "tool_names"]
)

agent = create_react_agent(
    llm=llm,
    tools=tools,
    prompt=agent_prompt
)

# ==================== Pydantic æ¨¡å‹ ====================

class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = "default"
    use_agent: bool = True

class ChatResponse(BaseModel):
    reply: str
    sources: Optional[List[str]] = []
    session_id: str
    timestamp: str
    thought_process: Optional[str] = None

class ContentGenerationRequest(BaseModel):
    topic: str
    style: str = "æ­£å¼"
    length: str = "ä¸­"
    context: Optional[str] = None

class IngestRequest(BaseModel):
    folder_path: str = "documents"

# ==================== å·¥å…·å‡½æ•¸ ====================

def verify_admin(authorization: Optional[str] = Header(None)):
    """é©—è­‰ç®¡ç†å“¡æ¬Šé™"""
    if authorization != f"Bearer {ADMIN_PASSWORD}":
        raise HTTPException(status_code=401, detail="æœªæˆæ¬Š")
    return True

def load_document(file_path: str):
    """è¼‰å…¥æ–‡ä»¶"""
    file_extension = Path(file_path).suffix.lower()
    
    try:
        if file_extension == ".pdf":
            loader = PyPDFLoader(file_path)
        elif file_extension in [".docx", ".doc"]:
            loader = Docx2txtLoader(file_path)
        elif file_extension == ".txt":
            loader = TextLoader(file_path, encoding="utf-8")
        else:
            logger.warning(f"ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {file_extension}")
            return []
        
        documents = loader.load()
        logger.info(f"âœ… è¼‰å…¥: {file_path} ({len(documents)} æ–‡ä»¶)")
        return documents
    except Exception as e:
        logger.error(f"âŒ è¼‰å…¥å¤±æ•— {file_path}: {str(e)}")
        return []

# ==================== Prompt æ¨¡æ¿ ====================

RAG_PROMPT = PromptTemplate(
    template="""ä½ æ˜¯å¸‚é•·çš„ AI åŠ©ç†ï¼Œè«‹æ ¹æ“šä»¥ä¸‹è³‡æ–™å›ç­”å•é¡Œã€‚

ç›¸é—œè³‡æ–™ï¼š
{context}

å°è©±è¨˜éŒ„ï¼š
{chat_history}

å•é¡Œï¼š{question}

å›ç­”æ™‚è«‹ï¼š
- ä½¿ç”¨å¸‚é•·è¦ªåˆ‡ã€å°ˆæ¥­çš„èªæ°£
- å¦‚æœè³‡æ–™ä¸­æ²’æœ‰ç­”æ¡ˆï¼Œè«‹èª å¯¦å‘ŠçŸ¥
- ä¿æŒç°¡æ½”æ˜ç­
- é©æ™‚ä½¿ç”¨è¼•é¬†çš„èªæ°£

å›ç­”ï¼š""",
    input_variables=["context", "chat_history", "question"]
)

CONTENT_PROMPT = PromptTemplate(
    template="""ä½ æ˜¯å¸‚é•·çš„å°ˆå±¬æ–‡æ¡ˆç”ŸæˆåŠ©ç†ã€‚

ä»»å‹™ï¼šç”Ÿæˆ {style} é¢¨æ ¼ã€{length} ç¯‡å¹…çš„æ–‡æ¡ˆ

ä¸»é¡Œï¼š{topic}

åƒè€ƒè³‡æ–™ï¼š
{context}

è¦æ±‚ï¼š
- å®Œå…¨æ¨¡ä»¿å¸‚é•·çš„èªæ°£å’Œç”¨è©ç¿’æ…£
- é¢¨æ ¼ï¼š{style}ï¼ˆæ­£å¼/è¼•é¬†/å¹½é»˜ï¼‰
- ç¯‡å¹…ï¼š{length}ï¼ˆçŸ­=50-100å­—ï¼Œä¸­=150-300å­—ï¼Œé•·=400-600å­—ï¼‰
- å…§å®¹å¿…é ˆåŸºæ–¼çŸ¥è­˜åº«è³‡è¨Š
- é¿å…è™›å‡å…§å®¹

æ–‡æ¡ˆå…§å®¹ï¼š""",
    input_variables=["topic", "style", "length", "context"]
)

# ==================== API ç«¯é» ====================

@app.get("/")
async def root():
    return {
        "system": "PAIS æ”¿å‹™åˆ†èº«æ™ºèƒ½ç³»çµ±",
        "version": "2.0.0",
        "framework": "LangChain (Agents + Memory + RAG + Tools)",
        "status": "ğŸŸ¢ é‹è¡Œä¸­"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    try:
        qdrant_client.get_collections()
        return {
            "status": "healthy",
            "qdrant": "âœ… connected",
            "llm": "âœ… Gemini Pro",
            "agents": "âœ… active"
        }
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}

@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    å°è©± API (LangChain Agent + Memory)
    """
    try:
        logger.info(f"ğŸ’¬ [{request.session_id}] å•é¡Œ: {request.message}")
        
        memory = get_memory(request.session_id)
        
        if request.use_agent:
            agent_executor = AgentExecutor(
                agent=agent,
                tools=tools,
                memory=memory,
                verbose=True,
                max_iterations=3,
                handle_parsing_errors=True
            )
            
            result = agent_executor.invoke({"input": request.message})
            reply = result["output"]
            thought_process = result.get("intermediate_steps", "")
            sources = []
            
        else:
            qa_chain = ConversationalRetrievalChain.from_llm(
                llm=llm,
                retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
                memory=memory,
                combine_docs_chain_kwargs={"prompt": RAG_PROMPT},
                return_source_documents=True
            )
            
            result = qa_chain({"question": request.message})
            reply = result["answer"]
            thought_process = None
            sources = [doc.metadata.get("source", "æœªçŸ¥") 
                      for doc in result.get("source_documents", [])]
        
        logger.info(f"âœ… å›ç­”: {reply[:100]}...")
        
        return ChatResponse(
            reply=reply,
            sources=sources,
            session_id=request.session_id,
            timestamp=datetime.now().isoformat(),
            thought_process=str(thought_process) if thought_process else None
        )
        
    except Exception as e:
        logger.error(f"âŒ å°è©±éŒ¯èª¤: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è™•ç†å¤±æ•—: {str(e)}")

@app.post("/api/generate")
async def generate_content(
    request: ContentGenerationRequest,
    admin: bool = Depends(verify_admin)
):
    """æ–‡æ¡ˆç”Ÿæˆ API"""
    try:
        logger.info(f"âœï¸ ç”Ÿæˆæ–‡æ¡ˆ: {request.topic}")
        
        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
        relevant_docs = retriever.get_relevant_documents(request.topic)
        context = "\n\n".join([doc.page_content for doc in relevant_docs])
        
        content_chain = LLMChain(
            llm=llm,
            prompt=CONTENT_PROMPT,
            verbose=True
        )
        
        result = content_chain.invoke({
            "topic": request.topic,
            "style": request.style,
            "length": request.length,
            "context": context if context else "ï¼ˆç„¡ç›¸é—œèƒŒæ™¯è³‡æ–™ï¼‰"
        })
        
        generated_content = result["text"]
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"generated_content/{timestamp}_{request.topic[:20]}.txt"
        Path("generated_content").mkdir(exist_ok=True)
        
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(f"ä¸»é¡Œ: {request.topic}\n")
            f.write(f"é¢¨æ ¼: {request.style}\n")
            f.write(f"ç¯‡å¹…: {request.length}\n")
            f.write(f"æ™‚é–“: {datetime.now().isoformat()}\n")
            f.write("=" * 50 + "\n\n")
            f.write(generated_content)
        
        logger.info(f"âœ… æ–‡æ¡ˆå·²å„²å­˜: {output_file}")
        
        return {
            "content": generated_content,
            "file_path": output_file,
            "sources": [doc.metadata.get("source", "æœªçŸ¥") for doc in relevant_docs],
            "context_used": len(relevant_docs)
        }
        
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¤±æ•—: {str(e)}")

@app.post("/api/ingest")
async def ingest_documents(
    request: IngestRequest,
    admin: bool = Depends(verify_admin)
):
    """çŸ¥è­˜åº«ä¸Šå‚³ API"""
    try:
        folder_path = Path(request.folder_path)
        if not folder_path.exists():
            raise HTTPException(status_code=404, detail="è³‡æ–™å¤¾ä¸å­˜åœ¨")
        
        supported_extensions = [".pdf", ".docx", ".doc", ".txt"]
        files = [f for f in folder_path.rglob("*") 
                if f.suffix.lower() in supported_extensions]
        
        if not files:
            return {"message": "è³‡æ–™å¤¾ä¸­æ²’æœ‰æ”¯æ´çš„æª”æ¡ˆ", "processed": 0}
        
        logger.info(f"ğŸ“š é–‹å§‹è™•ç† {len(files)} å€‹æª”æ¡ˆ")
        
        all_documents = []
        for file_path in files:
            docs = load_document(str(file_path))
            for doc in docs:
                doc.metadata["source"] = str(file_path)
                doc.metadata["uploaded_at"] = datetime.now().isoformat()
            all_documents.extend(docs)
        
        if not all_documents:
            return {"message": "ç„¡æ³•è¼‰å…¥ä»»ä½•æ–‡ä»¶", "processed": 0}
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", " ", ""],
            length_function=len
        )
        splits = text_splitter.split_documents(all_documents)
        
        logger.info(f"ğŸ“„ åˆ†å‰²å®Œæˆ: {len(splits)} å€‹ç‰‡æ®µ")
        
        vectorstore.add_documents(splits)
        
        logger.info(f"âœ… å‘é‡åŒ–å®Œæˆ")
        
        return {
            "message": "âœ… çŸ¥è­˜åº«æ›´æ–°æˆåŠŸ",
            "files_processed": len(files),
            "chunks_created": len(splits),
            "collection": COLLECTION_NAME
        }
        
    except Exception as e:
        logger.error(f"âŒ ä¸Šå‚³å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ä¸Šå‚³å¤±æ•—: {str(e)}")

@app.post("/api/upload")
async def upload_file(
    file: UploadFile = File(...),
    admin: bool = Depends(verify_admin)
):
    """å–®å€‹æª”æ¡ˆä¸Šå‚³"""
    try:
        file_path = Path("documents") / file.filename
        file_path.parent.mkdir(exist_ok=True)
        
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        logger.info(f"ğŸ“¤ ä¸Šå‚³: {file.filename}")
        
        docs = load_document(str(file_path))
        for doc in docs:
            doc.metadata["source"] = str(file_path)
        
        if docs:
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200
            )
            splits = text_splitter.split_documents(docs)
            vectorstore.add_documents(splits)
            
            return {
                "message": "âœ… æª”æ¡ˆä¸Šå‚³ä¸¦è™•ç†æˆåŠŸ",
                "filename": file.filename,
                "chunks": len(splits)
            }
        else:
            return {
                "message": "æª”æ¡ˆå·²ä¸Šå‚³ä½†ç„¡æ³•è™•ç†",
                "filename": file.filename
            }
            
    except Exception as e:
        logger.error(f"âŒ ä¸Šå‚³å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ä¸Šå‚³å¤±æ•—: {str(e)}")

@app.get("/api/memory/{session_id}")
async def get_memory_history(session_id: str):
    """å–å¾—å°è©±è¨˜æ†¶"""
    try:
        memory = get_memory(session_id)
        history = memory.load_memory_variables({})
        
        return {
            "session_id": session_id,
            "history": history
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/memory/{session_id}")
async def clear_memory(session_id: str, admin: bool = Depends(verify_admin)):
    """æ¸…é™¤å°è©±è¨˜æ†¶"""
    try:
        if session_id in memory_store:
            memory_store[session_id].clear()
            del memory_store[session_id]
            
            history_file = Path(f"chat_history/{session_id}.json")
            if history_file.exists():
                history_file.unlink()
            
            logger.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤è¨˜æ†¶: {session_id}")
            
        return {"message": f"âœ… å·²æ¸…é™¤ {session_id} çš„è¨˜æ†¶"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/stats")
async def get_stats():
    """ç³»çµ±çµ±è¨ˆ"""
    try:
        collection_info = qdrant_client.get_collection(COLLECTION_NAME)
        
        return {
            "collection_name": COLLECTION_NAME,
            "total_vectors": collection_info.vectors_count,
            "active_sessions": len(memory_store),
            "framework": "LangChain",
            "components": {
                "agents": "âœ… ReAct Agent",
                "memory": "âœ… ConversationBufferMemory",
                "rag": "âœ… ConversationalRetrievalChain",
                "tools": len(tools)
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.on_event("startup")
async def startup_event():
    logger.info("ğŸš€ PAIS ç³»çµ±å•Ÿå‹• (LangChain Powered)")
    logger.info(f"ğŸ“ Qdrant: {QDRANT_HOST}:{QDRANT_PORT}")
    logger.info(f"ğŸ“š é›†åˆ: {COLLECTION_NAME}")
    logger.info(f"ğŸ¤– Agents: {len(tools)} å·¥å…·")
    logger.info(f"ğŸ§  Memory: ConversationBufferMemory")
    
    Path("chat_history").mkdir(exist_ok=True)
    Path("generated_content").mkdir(exist_ok=True)
    Path("logs").mkdir(exist_ok=True)

@app.on_event("shutdown")
async def shutdown_event():
    logger.info("â¹ PAIS ç³»çµ±é—œé–‰")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)